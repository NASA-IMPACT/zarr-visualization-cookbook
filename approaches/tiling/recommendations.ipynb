{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e2cd6c-9a91-459b-8410-5712b65ed46d",
   "metadata": {},
   "source": [
    "# Recommendations\n",
    "\n",
    "## Data Format\n",
    "\n",
    "* **Data Format:** At this time, COG + pgSTAC tiling performs better than tiling Zarr or kerchunk references, at all zoom levels.\n",
    "* **Kerchunk Reference Files:** The performance of tiling using a kerchunk reference can be as good or better than a zarr store. It is important to consider this is when the NetCDF files' chunks are the same as the zarr store version. \n",
    "\n",
    "## Zarr-specific Recommendations\n",
    "\n",
    "* **Ensure no zarr coordinate chunking:** Ensure coordinate data is not being chunked. If coordinates are being chunked, it will result in more files being opened during xarray.open_dataset and cause significant performance degradation.\n",
    "* **Smaller chunk sizes perform better:** Chunk size significantly impacts performance. A specific recommendation depends on the performance requirements of the application.\n",
    "* **Fewer spatial chunks perform better:** A greater number of chunks, spatially, will impact performance especially at low zoom levels as more chunks are loaded for greater spatial coverage.\n",
    "* **Pyramids improve performance for high resolution datasets:** High resolution datasets will suffer having either large chunks or many chunks, or both. To provide a good experience, zarr data can be aggregated into multiscale datasets, otherwise known as pyramids.\n",
    "\n",
    "## What is high resolution?\n",
    "\n",
    "Given the current performance of titiler-xarray in [tile-server-e2e-benchmarks.ipynb](./tile-server-e2e-benchmarks.ipynb) and assuming you are targeting 300ms or less, it would be suggested to target 8mb or smaller for your chunks.\n",
    "\n",
    "To give a sense of what this means in terms of spatial resolution, and assuming a global dataset where the full spatial extent is stored in a single chunk, you would have the following dimensions of your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f046a8c-7c6f-4b9e-b0d5-7eb08fc23d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For data type float16, an 8MB dataset, spatially, would have:\n",
      "* Dimensions: 1448.0 x 2896.0\n",
      "* Degrees (assuming global data): 0.124° x 0.124°\n",
      "\n",
      "For data type float32, an 8MB dataset, spatially, would have:\n",
      "* Dimensions: 1024.0 x 2048.0\n",
      "* Degrees (assuming global data): 0.176° x 0.176°\n",
      "\n",
      "For data type float64, an 8MB dataset, spatially, would have:\n",
      "* Dimensions: 724.0 x 1448.0\n",
      "* Degrees (assuming global data): 0.249° x 0.249°\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "datatypes = [\"float16\", \"float32\", \"float64\"]\n",
    "total_global_chunk_size_mb = 8\n",
    "\n",
    "for data_type in datatypes:\n",
    "    # Determine the size in bytes of each data value\n",
    "    dtype = np.dtype(data_type)\n",
    "    # calcuate the itemsize in megabytes\n",
    "    itemsize_mb = dtype.itemsize/1024/1024\n",
    "    y_dim = np.sqrt(total_global_chunk_size_mb/2/itemsize_mb)\n",
    "    x_dim = y_dim * 2\n",
    "    print(f\"For data type {dtype}, an 8MB dataset, spatially, would have:\")\n",
    "    print(f\"* Dimensions: {np.round(y_dim)} x {np.round(x_dim)}\")\n",
    "    print(f\"* Spatial resolution of values, assuming global data: {np.round(180/y_dim, 3)}° x {np.round(360/x_dim, 3)}°\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47fecd-8b18-414b-bc55-eaadcf286c30",
   "metadata": {},
   "source": [
    "If your dataset has a higher resolution than what is listed above, you will either want to chunk your data spatially or create a pyramid or both. Having spatially chunked data can also impact performance at low zoom levels, so you should try chunks significantly  smaller than 8MB, say 4MB. Assuming the spatial extent of your data is larger than 16MB, you will probably want to create a pyramid.\n",
    "\n",
    "It's common to prefer larger chunk sizes for analysis workflows. These situations may motivate creating pyramids with small chunks for visualization purposes.\n",
    "\n",
    "The Zarr V3 [sharding extension](https://zarr.dev/zeps/draft/ZEP0002.html) may help in the future with the trade-off between chunk size and number of chunks at different zoom levels. Sharding stores multiple chunks together in one object, so range requests for small chunks will still work for high (zoomed in) zoom levels while the potential to concatenate adjacent ranges into a single request means multiple chunks or an entire shard could be read in one request for low (zoomed out) zoom levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
