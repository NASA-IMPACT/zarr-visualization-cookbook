{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"End-to-End Benchmarking\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing benchmark results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies\n",
    "\n",
    "The CarbonPlan team put together some utilities for parsing, processing, and visualizing the benchmarking results in [carbonplan_benchmarks](https://github.com/carbonplan/benchmark-maps). We'll use those utilities along with the [Holoviz](https://holoviz.org/) HoloViz suite of tools for visualization and [Pandas](https://pandas.pydata.org/) as the underlying analysis tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carbonplan_benchmarks.analysis as cba\n",
    "import hvplot\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = 'holoviews'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benchmark results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the paths to the baseline images that the tests will be compared against and paths to the metadata files associated with each benchmarking run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fp = \"s3://carbonplan-benchmarks/benchmark-data/baselines.json\"\n",
    "metadata_base_fp = 's3://carbonplan-benchmarks/benchmark-data'\n",
    "metadata_files = [\n",
    "    'data-2023-08-04T01-14-24.json',\n",
    "    'data-2023-08-04T01-15-30.json',\n",
    "    'data-2023-08-04T01-16-27.json',\n",
    "    'data-2023-08-04T01-17-25.json',\n",
    "    'data-2023-08-04T01-18-37.json',\n",
    "    'data-2023-08-04T01-19-47.json',\n",
    "    'data-2023-08-04T01-21-02.json',\n",
    "    'data-2023-08-04T01-22-08.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the utilities from `carbonplan_benchmarks` to load the metadata and baseline images into DataFrames, process those results, and create a summary DataFrame for all runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = cba.load_snapshots(snapshot_path=baseline_fp)\n",
    "summary_dfs = []\n",
    "for file in metadata_files:\n",
    "    fp = f\"{metadata_base_fp}/{file}\"\n",
    "    metadata, trace_events = cba.load_data(metadata_path=fp, run=0)\n",
    "    data = cba.process_run(metadata=metadata, trace_events=trace_events, snapshots=snapshots)\n",
    "    summary_dfs.append(cba.create_summary(metadata=metadata, data=data))\n",
    "summary = pd.concat(summary_dfs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.head(n=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see how the duration of each action changes as a function of the zoom level. An important piece of context is that the underlying dataset only has four pyramid levels, so zoom=4 does not need to fetch any new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.plot.scatter(x='zoom', y='duration', by='zarr_version')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's instead show the duration as a function of the chunk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.plot.scatter(x='chunk_size', y='duration', by='zarr_version')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the request duration as a funciton of the chunk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.plot.scatter(x='chunk_size', y='request_duration', by='zarr_version')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's look at the fraction of time that's spent fetching data as a function of the chunk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.plot.scatter(x='chunk_size', y='request_percent', by='zarr_version').opts(ylim=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark-maps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
